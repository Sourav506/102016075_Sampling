{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c094809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e77c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Creditcard_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5688d2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8dec4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d8d265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Class\", data=data)\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Binary Class Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b833d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,1:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83b0eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d27148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be5309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      " 0    0.988655\n",
      "1    0.011345\n",
      "Name: Class, dtype: float64\n",
      "Testing set class distribution:\n",
      " 0    0.987097\n",
      "1    0.012903\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_class_dist = y_train.value_counts(normalize=True)\n",
    "test_class_dist = y_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"Training set class distribution:\\n\", train_class_dist)\n",
    "print(\"Testing set class distribution:\\n\", test_class_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6685eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(617, 28)\n",
      "(617,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d388bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train_resampled) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b612a186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       153\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       1.00      0.75      0.83       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# create a list of classifiers to train\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "\n",
    "# train each model on each sample and print the classification report\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"\\t{model_name}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "160d5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0842c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       153\n",
      "           1       0.10      0.50      0.17         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.57       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       153\n",
      "           1       0.10      0.50      0.17         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.57       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       153\n",
      "           1       0.08      0.50      0.13         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.53      0.71      0.54       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       153\n",
      "           1       0.08      0.50      0.13         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.53      0.71      0.54       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       153\n",
      "           1       0.06      0.50      0.11         2\n",
      "\n",
      "    accuracy                           0.90       155\n",
      "   macro avg       0.53      0.70      0.53       155\n",
      "weighted avg       0.98      0.90      0.93       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93       153\n",
      "           1       0.05      0.50      0.09         2\n",
      "\n",
      "    accuracy                           0.86       155\n",
      "   macro avg       0.52      0.68      0.51       155\n",
      "weighted avg       0.98      0.86      0.92       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       153\n",
      "           1       0.06      0.50      0.11         2\n",
      "\n",
      "    accuracy                           0.90       155\n",
      "   macro avg       0.53      0.70      0.53       155\n",
      "weighted avg       0.98      0.90      0.93       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# create a list of classifiers to train\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "\n",
    "# train each model on each sample and print the classification report\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"\\t{model_name}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9866e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7051c1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88       155\n",
      "   macro avg       0.49      0.45      0.47       155\n",
      "weighted avg       0.97      0.88      0.93       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.49      0.48      0.49       155\n",
      "weighted avg       0.97      0.94      0.96       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       153\n",
      "           1       0.06      0.50      0.11         2\n",
      "\n",
      "    accuracy                           0.90       155\n",
      "   macro avg       0.53      0.70      0.53       155\n",
      "weighted avg       0.98      0.90      0.93       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.49      0.46      0.48       155\n",
      "weighted avg       0.97      0.92      0.94       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       153\n",
      "           1       0.04      0.50      0.08         2\n",
      "\n",
      "    accuracy                           0.85       155\n",
      "   macro avg       0.52      0.67      0.50       155\n",
      "weighted avg       0.98      0.85      0.90       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       153\n",
      "           1       0.10      0.50      0.17         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.57       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       153\n",
      "           1       0.07      0.50      0.12         2\n",
      "\n",
      "    accuracy                           0.90       155\n",
      "   macro avg       0.53      0.70      0.53       155\n",
      "weighted avg       0.98      0.90      0.94       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       153\n",
      "           1       0.07      0.50      0.12         2\n",
      "\n",
      "    accuracy                           0.91       155\n",
      "   macro avg       0.53      0.71      0.54       155\n",
      "weighted avg       0.98      0.91      0.94       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       153\n",
      "           1       1.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.99      0.50      0.50       155\n",
      "weighted avg       0.99      0.99      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       153\n",
      "           1       1.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.99      0.50      0.50       155\n",
      "weighted avg       0.99      0.99      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.49      0.49      0.49       155\n",
      "weighted avg       0.97      0.96      0.97       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.49      0.47      0.48       155\n",
      "weighted avg       0.97      0.92      0.95       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# create a list of classifiers to train\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "\n",
    "# train each model on each sample and print the classification report\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"\\t{model_name}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2a207f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADASYN sampling\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "sample_size = len(X_train) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce2e9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.58      0.73      0.62       155\n",
      "weighted avg       0.98      0.96      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       153\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.62      0.74      0.66       155\n",
      "weighted avg       0.98      0.97      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88       155\n",
      "   macro avg       0.49      0.44      0.47       155\n",
      "weighted avg       0.97      0.88      0.92       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.49      0.48      0.49       155\n",
      "weighted avg       0.97      0.94      0.96       155\n",
      "\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       153\n",
      "           1       0.06      0.50      0.11         2\n",
      "\n",
      "    accuracy                           0.90       155\n",
      "   macro avg       0.53      0.70      0.53       155\n",
      "weighted avg       0.98      0.90      0.93       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.12      0.50      0.20         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.56      0.73      0.59       155\n",
      "weighted avg       0.98      0.95      0.96       155\n",
      "\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.49      0.46      0.48       155\n",
      "weighted avg       0.97      0.92      0.94       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.66      0.74      0.70       155\n",
      "weighted avg       0.98      0.98      0.98       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.09      0.50      0.15         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.54      0.72      0.56       155\n",
      "weighted avg       0.98      0.93      0.95       155\n",
      "\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       153\n",
      "           1       0.04      0.50      0.08         2\n",
      "\n",
      "    accuracy                           0.85       155\n",
      "   macro avg       0.52      0.67      0.50       155\n",
      "weighted avg       0.98      0.85      0.90       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.97       155\n",
      "   macro avg       0.60      0.74      0.63       155\n",
      "weighted avg       0.98      0.97      0.97       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.08      0.50      0.14         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.54      0.71      0.55       155\n",
      "weighted avg       0.98      0.92      0.95       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       153\n",
      "           1       0.07      0.50      0.12         2\n",
      "\n",
      "    accuracy                           0.90       155\n",
      "   macro avg       0.53      0.70      0.53       155\n",
      "weighted avg       0.98      0.90      0.94       155\n",
      "\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       153\n",
      "           1       0.07      0.50      0.12         2\n",
      "\n",
      "    accuracy                           0.91       155\n",
      "   macro avg       0.53      0.71      0.54       155\n",
      "weighted avg       0.98      0.91      0.94       155\n",
      "\n",
      "\tRandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.98       155\n",
      "   macro avg       0.49      0.50      0.50       155\n",
      "weighted avg       0.97      0.98      0.98       155\n",
      "\n",
      "\tExtraTreesClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       153\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.99       155\n",
      "   macro avg       0.75      0.75      0.75       155\n",
      "weighted avg       0.99      0.99      0.99       155\n",
      "\n",
      "\tGradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.49      0.48      0.49       155\n",
      "weighted avg       0.97      0.95      0.96       155\n",
      "\n",
      "\tXGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       155\n",
      "   macro avg       0.49      0.47      0.48       155\n",
      "weighted avg       0.97      0.92      0.95       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# create a list of classifiers to train\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "\n",
    "# train each model on each sample and print the classification report\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"\\t{model_name}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, zero_division=1)\n",
    "        print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "464e0cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       153\n",
      "           1       0.14      0.50      0.22         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.57      0.73      0.60       155\n",
      "weighted avg       0.98      0.95      0.97       155\n",
      "\n",
      "Sample 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       155\n",
      "   macro avg       0.49      0.47      0.48       155\n",
      "weighted avg       0.97      0.93      0.95       155\n",
      "\n",
      "Sample 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       155\n",
      "   macro avg       0.49      0.48      0.49       155\n",
      "weighted avg       0.97      0.95      0.96       155\n",
      "\n",
      "Sample 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.96       155\n",
      "   macro avg       0.49      0.49      0.49       155\n",
      "weighted avg       0.97      0.96      0.97       155\n",
      "\n",
      "Sample 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       153\n",
      "           1       0.11      0.50      0.18         2\n",
      "\n",
      "    accuracy                           0.94       155\n",
      "   macro avg       0.55      0.72      0.58       155\n",
      "weighted avg       0.98      0.94      0.96       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "bbc = BalancedBaggingClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "# create 5 samples\n",
    "sample_size = len(X_train_resampled) // 5\n",
    "samples = []\n",
    "for i in range(5):\n",
    "    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n",
    "    X_sample = X_train_resampled.iloc[sample_indices, :]\n",
    "    y_sample = y_train_resampled.iloc[sample_indices]\n",
    "    samples.append((X_sample, y_sample))\n",
    "\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    bbc.fit(X_sample, y_sample)\n",
    "    y_pred = bbc.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e2f4034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.012\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.088\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.507\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.089\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.131\n",
      "Sample 2:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.056\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.089\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.033\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.034\n",
      "Sample 3:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.067\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.513\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.089\n",
      "Sample 4:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.047\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.090\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.068\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.038\n",
      "Sample 5:\n",
      "\tAdaBoostClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tRandomForestClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tExtraTreesClassifier:\n",
      "\t\tPR AUC: 0.506\n",
      "\tGradientBoostingClassifier:\n",
      "\t\tPR AUC: 0.505\n",
      "\tXGBClassifier:\n",
      "\t\tPR AUC: 0.508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "models = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n",
    "\n",
    "for i, (X_sample, y_sample) in enumerate(samples):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    for model in models:\n",
    "        print(f\"\\t{model.__class__.__name__}:\")\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        print(f\"\\t\\tPR AUC: {pr_auc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "734da60e4afcdc8d62a7a88b64d8aa0d635fe9b122d4fae64989ab3a1e8e7652"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
